{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 14:25:06.218520: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-14 14:25:06.255716: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-14 14:25:06.818776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "def positional_encoding(length: int, depth: int):\n",
    "    \"\"\"\n",
    "    Generates a positional encoding for a given length and depth.\n",
    "\n",
    "    Args:\n",
    "        length (int): The length of the input sequence.\n",
    "        depth (int): The depth that represents the dimensionality of the encoding.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The positional encoding of shape (length, depth).\n",
    "    \"\"\"\n",
    "    depth = depth / 2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1) \n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A positional embedding layer combines the input embedding with a positional encoding that helps the Transformer\n",
    "    to understand the relative position of the input tokens. This layer takes the input of tokens and converts them\n",
    "    into sequence of embeddings vector. Then, it adds the positional encoding to the embeddings.\n",
    "\n",
    "    Methods:\n",
    "        compute_mask: Computes the mask to be applied to the embeddings.\n",
    "        call: Performs the forward pass of the layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, d_model: int, embedding: tf.keras.layers.Embedding=None):\n",
    "        \"\"\" Constructor of the PositionalEmbedding layer.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): The size of the vocabulary. I. e. the number of unique tokens in the input sequence.\n",
    "            d_model (int): The dimensionality of the embedding vector.\n",
    "            embedding (tf.keras.layers.Embedding): The custom embedding layer. If None, a default embedding layer will be created.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) if embedding is None else embedding\n",
    "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        \"\"\" Computes the mask to be applied to the embeddings.\n",
    "        \"\"\"\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\" Performs the forward pass of the layer.\n",
    "        \n",
    "        Args:\n",
    "            x (tf.Tensor): The input tensor of shape (batch_size, seq_length).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of embedding vectors with added positional information. The shape is\n",
    "                (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        length = tf.shape(x)[1]\n",
    "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_input shape (1, 100)\n",
      "PositionalEmbedding output (1, 100, 512)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "random_input = np.random.randint(0, vocab_size, size=(1, 100))\n",
    "\n",
    "output = embedding_layer(random_input)\n",
    "print(\"random_input shape\", random_input.shape)\n",
    "print(\"PositionalEmbedding output\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Base class for all attention layers. It contains the common functionality of all attention layers.\n",
    "    This layer contains a MultiHeadAttention layer, a LayerNormalization layer and an Add layer.\n",
    "    It is used as a base class for the GlobalSelfAttention, CausalSelfAttention and CrossAttention layers.\n",
    "    And it is not intended to be used directly.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        mha (tf.keras.layers.MultiHeadAttention): The MultiHeadAttention layer.\n",
    "        layernorm (tf.keras.layers.LayerNormalization): The LayerNormalization layer.\n",
    "        add (tf.keras.layers.Add): The Add layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs: dict):\n",
    "        \"\"\" Constructor of the BaseAttention layer.\n",
    "        \n",
    "        Args:\n",
    "            **kwargs: Additional keyword arguments that are passed to the MultiHeadAttention layer, e. g. \n",
    "                        num_heads (number of heads), key_dim (dimensionality of the key space), etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "    \"\"\"\n",
    "    A class that implements the cross-attention layer by inheriting from the BaseAttention class.\n",
    "    This layer is used to process two different sequences and attends to the context sequence while processing the query sequence.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.    \n",
    "\n",
    "    Attributes:\n",
    "        mha (tf.keras.layers.MultiHeadAttention): The MultiHeadAttention layer.\n",
    "        layernorm (tf.keras.layers.LayerNormalization): The LayerNormalization layer.\n",
    "        add (tf.keras.layers.Add): The Add layer.\n",
    "    \"\"\"\n",
    "    def call(self, x: tf.Tensor, context: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the cross-attention operation.\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The query (expected Transformer results) sequence of shape (batch_size, seq_length, d_model).\n",
    "            context (tf.Tensor): The context (inputs to the Encoder layer) sequence of shape (batch_size, seq_length, d_model).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        attn_output, attn_scores = self.mha(query=x, key=context, value=context, return_attention_scores=True)\n",
    "\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "    \"\"\"\n",
    "    A class that implements the global self-attention layer by inheriting from the BaseAttention class.\n",
    "    This layer is used to process a single sequence and attends to all the tokens in the sequence.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        mha (tf.keras.layers.MultiHeadAttention): The MultiHeadAttention layer.\n",
    "        layernorm (tf.keras.layers.LayerNormalization): The LayerNormalization layer.\n",
    "        add (tf.keras.layers.Add): The Add layer.\n",
    "    \"\"\"\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the global self-attention operation.\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length, d_model).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        attn_output = self.mha(query=x, value=x, key=x)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "    \"\"\"\n",
    "    Call self attention on the input sequence, ensuring that each position in the \n",
    "    output depends only on previous positions (i.e. a causal model).\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        mha (tf.keras.layers.MultiHeadAttention): The MultiHeadAttention layer.\n",
    "        layernorm (tf.keras.layers.LayerNormalization): The LayerNormalization layer.\n",
    "        add (tf.keras.layers.Add): The Add layer.\n",
    "    \"\"\"\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the causal self-attention operation.\n",
    "        \n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length, d_model).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        attn_output = self.mha(query=x, value=x, key=x, use_causal_mask = True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_embeddings shape (1, 100, 512)\n",
      "decoder_embeddings shape (1, 110, 512)\n",
      "cross_attention_output shape (1, 110, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'cross_attention' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab_size = 1000\n",
    "decoder_vocab_size = 1100\n",
    "d_model = 512\n",
    "\n",
    "encoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "decoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "\n",
    "random_encoder_input = np.random.randint(0, encoder_vocab_size, size=(1, 100))\n",
    "random_decoder_input = np.random.randint(0, decoder_vocab_size, size=(1, 110))\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(random_encoder_input)\n",
    "decoder_embeddings = decoder_embedding_layer(random_decoder_input)\n",
    "\n",
    "print(\"encoder_embeddings shape\", encoder_embeddings.shape)\n",
    "print(\"decoder_embeddings shape\", decoder_embeddings.shape)\n",
    "\n",
    "cross_attention_layer = CrossAttention(num_heads=2, key_dim=512)\n",
    "cross_attention_output = cross_attention_layer(decoder_embeddings, encoder_embeddings)\n",
    "\n",
    "print(\"cross_attention_output shape\", cross_attention_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_embeddings shape (1, 100, 512)\n",
      "global_self_attention_output shape (1, 100, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'global_self_attention' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "encoder_embedding_layer = PositionalEmbedding(vocab_size, d_model)\n",
    "\n",
    "random_encoder_input = np.random.randint(0, encoder_vocab_size, size=(1, 100))\n",
    "\n",
    "encoder_embeddings = encoder_embedding_layer(random_encoder_input)\n",
    "\n",
    "print(\"encoder_embeddings shape\", encoder_embeddings.shape)\n",
    "\n",
    "cross_attention_layer = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
    "cross_attention_output = cross_attention_layer(encoder_embeddings)\n",
    "\n",
    "print(\"global_self_attention_output shape\", cross_attention_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A class that implements the feed-forward layer.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        seq (tf.keras.Sequential): The sequential layer that contains the feed-forward layers. It applies the two feed-forward layers and the dropout layer.\n",
    "        add (tf.keras.layers.Add): The Add layer.\n",
    "        layer_norm (tf.keras.layers.LayerNormalization): The LayerNormalization layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, dff: int, dropout_rate: float=0.1):\n",
    "        \"\"\"\n",
    "        Constructor of the FeedForward layer.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            dff (int): The dimensionality of the feed-forward layer.\n",
    "            dropout_rate (float): The dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the feed-forward operation. \n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length, d_model).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A single layer of the Encoder. Usually there are multiple layers stacked on top of each other.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        self_attention (GlobalSelfAttention): The global self-attention layer.\n",
    "        ffn (FeedForward): The feed-forward layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, num_heads: int, dff: int, dropout_rate: float=0.1):\n",
    "        \"\"\"\n",
    "        Constructor of the EncoderLayer.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            num_heads (int): The number of heads in the multi-head attention layer.\n",
    "            dff (int): The dimensionality of the feed-forward layer.\n",
    "            dropout_rate (float): The dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attention = GlobalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate\n",
    "            )\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the forward pass of the layer.\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length, d_model).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        x = self.self_attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A custom TensorFlow layer that implements the Encoder. This layer is mostly used in the Transformer models \n",
    "    for natural language processing tasks, such as machine translation, text summarization or text classification.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        d_model (int): The dimensionality of the model.\n",
    "        num_layers (int): The number of layers in the encoder.\n",
    "        pos_embedding (PositionalEmbedding): The positional embedding layer.\n",
    "        enc_layers (list): The list of encoder layers.\n",
    "        dropout (tf.keras.layers.Dropout): The dropout layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers: int, d_model: int, num_heads: int, dff: int, vocab_size: int, dropout_rate: float=0.1):\n",
    "        \"\"\"\n",
    "        Constructor of the Encoder.\n",
    "\n",
    "        Args:\n",
    "            num_layers (int): The number of layers in the encoder.\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            num_heads (int): The number of heads in the multi-head attention layer.\n",
    "            dff (int): The dimensionality of the feed-forward layer.\n",
    "            vocab_size (int): The size of the vocabulary.\n",
    "            dropout_rate (float): The dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model=d_model,\n",
    "                        num_heads=num_heads,\n",
    "                        dff=dff,\n",
    "                        dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the forward pass of the layer.\n",
    "        \n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length).\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: The output sequence of shape (batch_size, seq_length, d_model).\n",
    "        \"\"\"\n",
    "        x = self.pos_embedding(x)  \n",
    "        # here x has shape `(batch_size, seq_len, d_model)`\n",
    "\n",
    "        # Add dropout.\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'global_self_attention_1' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'encoder_layer' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_encoder_input shape (1, 100)\n",
      "encoder_output shape (1, 100, 512)\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab_size = 1000\n",
    "d_model = 512\n",
    "\n",
    "encoder = Encoder(num_layers=2, d_model=d_model, num_heads=2, dff=2048, vocab_size=encoder_vocab_size)\n",
    "\n",
    "random_encoder_input = np.random.randint(0, encoder_vocab_size, size=(1, 100))\n",
    "\n",
    "encoder_output = encoder(random_encoder_input)\n",
    "\n",
    "print(\"random_encoder_input shape\", random_encoder_input.shape)\n",
    "print(\"encoder_output shape\", encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A single layer of the Decoder. Usually there are multiple layers stacked on top of each other.\n",
    "    \n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        causal_self_attention (CausalSelfAttention): The causal self-attention layer.\n",
    "        cross_attention (CrossAttention): The cross-attention layer.\n",
    "        ffn (FeedForward): The feed-forward layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, num_heads: int, dff: int, dropout_rate: float=0.1):\n",
    "        \"\"\"\n",
    "        Constructor of the DecoderLayer.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            num_heads (int): The number of heads in the multi-head attention layer.\n",
    "            dff (int): The dimensionality of the feed-forward layer.\n",
    "            dropout_rate (float): The dropout rate. \n",
    "        \"\"\"\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.causal_self_attention = CausalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate)\n",
    "\n",
    "        self.cross_attention = CrossAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate)\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x: tf.Tensor, context: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the forward pass of the layer.\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, seq_length, d_model). x is usually the output of the previous decoder layer.\n",
    "            context (tf.Tensor): The context sequence of shape (batch_size, seq_length, d_model). Context is usually the output of the encoder.\n",
    "        \"\"\"\n",
    "        x = self.causal_self_attention(x=x)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "        # Cache the last attention scores for plotting later\n",
    "        self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    A custom TensorFlow layer that implements the Decoder. This layer is mostly used in the Transformer models\n",
    "    for natural language processing tasks, such as machine translation, text summarization or text classification.\n",
    "\n",
    "    Methods:\n",
    "        call: Performs the forward pass of the layer.\n",
    "\n",
    "    Attributes:\n",
    "        d_model (int): The dimensionality of the model.\n",
    "        num_layers (int): The number of layers in the decoder.\n",
    "        pos_embedding (PositionalEmbedding): The positional embedding layer.\n",
    "        dec_layers (list): The list of decoder layers.\n",
    "        dropout (tf.keras.layers.Dropout): The dropout layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers: int, d_model: int, num_heads: int, dff: int, vocab_size: int, dropout_rate: float=0.1):\n",
    "        \"\"\"\n",
    "        Constructor of the Decoder.\n",
    "\n",
    "        Args:\n",
    "            num_layers (int): The number of layers in the decoder.\n",
    "            d_model (int): The dimensionality of the model.\n",
    "            num_heads (int): The number of heads in the multi-head attention layer.\n",
    "            dff (int): The dimensionality of the feed-forward layer.\n",
    "            vocab_size (int): The size of the vocabulary.\n",
    "            dropout_rate (float): The dropout rate.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(\n",
    "                d_model=d_model, \n",
    "                num_heads=num_heads, \n",
    "                dff=dff, \n",
    "                dropout_rate=dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def call(self, x: tf.Tensor, context: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        The call function that performs the forward pass of the layer.\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): The input sequence of shape (batch_size, target_seq_len).\n",
    "            context (tf.Tensor): The context sequence of shape (batch_size, input_seq_len, d_model).\n",
    "        \"\"\"\n",
    "        # `x` is token-IDs shape (batch, target_seq_len)\n",
    "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x  = self.dec_layers[i](x, context)\n",
    "\n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformer(\n",
    "    input_vocab_size: int, \n",
    "    target_vocab_size: int, \n",
    "    encoder_input_size: int = None,\n",
    "    decoder_input_size: int = None,\n",
    "    num_layers: int=6, \n",
    "    d_model: int=512, \n",
    "    num_heads: int=8,\n",
    "    dff: int=2048,\n",
    "    dropout_rate: float=0.1,\n",
    "    ) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    A custom TensorFlow model that implements the Transformer architecture.\n",
    "\n",
    "    Args:\n",
    "        input_vocab_size (int): The size of the input vocabulary.\n",
    "        target_vocab_size (int): The size of the target vocabulary.\n",
    "        encoder_input_size (int): The size of the encoder input sequence.\n",
    "        decoder_input_size (int): The size of the decoder input sequence.\n",
    "        num_layers (int): The number of layers in the encoder and decoder.\n",
    "        d_model (int): The dimensionality of the model.\n",
    "        num_heads (int): The number of heads in the multi-head attention layer.\n",
    "        dff (int): The dimensionality of the feed-forward layer.\n",
    "        dropout_rate (float): The dropout rate.\n",
    "\n",
    "    Returns:\n",
    "        A TensorFlow Keras model.\n",
    "    \"\"\"\n",
    "    inputs = [\n",
    "        tf.keras.layers.Input(shape=(encoder_input_size,), dtype=tf.int64), \n",
    "        tf.keras.layers.Input(shape=(decoder_input_size,), dtype=tf.int64)\n",
    "        ]\n",
    "    \n",
    "    encoder_input, decoder_input = inputs\n",
    "\n",
    "    encoder = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=input_vocab_size, dropout_rate=dropout_rate)(encoder_input)\n",
    "    decoder = Decoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=target_vocab_size, dropout_rate=dropout_rate)(decoder_input, encoder)\n",
    "\n",
    "    output = tf.keras.layers.Dense(target_vocab_size)(decoder)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'global_self_attention_3' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'encoder_layer_2' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'causal_self_attention' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/opt/envs/ai-explorer/lib/python3.10/site-packages/keras/src/layers/layer.py:857: UserWarning: Layer 'decoder_layer' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,768,192</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,971,712</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">513,000</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_1 (\u001b[38;5;33mEncoder\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │  \u001b[38;5;34m5,768,192\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder (\u001b[38;5;33mDecoder\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │  \u001b[38;5;34m9,971,712\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m1000\u001b[0m) │    \u001b[38;5;34m513,000\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,252,904</span> (62.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,252,904\u001b[0m (62.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,252,904</span> (62.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,252,904\u001b[0m (62.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_input_size = 100\n",
    "decoder_input_size = 110\n",
    "\n",
    "encoder_vocab_size = 1000\n",
    "decoder_vocab_size = 1000\n",
    "\n",
    "model = Transformer(\n",
    "    input_vocab_size=encoder_vocab_size,\n",
    "    target_vocab_size=decoder_vocab_size,\n",
    "    encoder_input_size=encoder_input_size,\n",
    "    decoder_input_size=decoder_input_size,\n",
    "    num_layers=2,\n",
    "    d_model=512,\n",
    "    num_heads=2,\n",
    "    dff=512,\n",
    "    dropout_rate=0.1)\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-explorer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
